#!/usr/bin/env python3

import argparse
import csv
import getpass
import os.path
import requests
import sys
import time

from common import IriMaps, split_gate, tokenize


def preferize(gates, gate_mappings, special_gates, preferred, symbols):
  """
  'Preferize' a tokenised list of gates by replacing gate labels with preferred labels

  Parameters:
      gates: list of strings describing gates
      gate_mappings: dict containing mappings of gate labels to ontology ids
      special_gates: additional information regarding a certain number of special gates.
      symbols: list of suffix symbols
  """
  preferred_label_gates = []
  for gate in gates:
    label, suffixsymb = split_gate(gate, symbols)
    # Get any label / ontology id pairs corresponding to the synonym represented by `gate` from
    # the special_gates dictionary. Note that we match case-insensitively to the special_gates
    # dictionary
    special_entries = [
      {'label': key, 'ontid': val['Ontology ID']}
      for key, val in special_gates.items()
      if label and (
          label.casefold() == key.casefold() or
          label.casefold() in [v.casefold() for v in val['Synonyms'].split(', ')] or
          label.casefold() in [v.casefold() for v in val['Toxic Synonym'] .split(', ')])]

    # This shouldn't happen unless there are duplicate names in the special gates file:
    if special_entries and len(special_entries) > 1:
      print("Warning: {} ontology ids found with label: '{}'"
            .format(len(special_entries), gate))

    # Now try to find the ontology id in the gate_mappings map. If it isn't there, check to
    # see if it has a synonym in the map of special gates. If we don't find it there either, then
    # prefix the gate with a '!'.
    ontology_id = gate_mappings.get(label)
    if not ontology_id:
      # If this gate is a synonym of a special gate, then look up its ontology id there:
      ontology_id = special_entries[0]['ontid'] if special_entries else "!{}".format(label)

    # Look up the preferred label for a gate based on the ontology id. If we can't find it in the
    # preferred gates list, check to see if it is the synonym of a special gate and if so, use that
    # label. Otherwise prefix it with a '!'.
    preferred_label = (preferred.get(ontology_id, special_entries[0]['label']
                                     if special_entries else '!{}'.format(label)))
    preferred_label_gates.append(preferred_label + suffixsymb)

  return preferred_label_gates


def validate(reported, project, suffixsymbs, suffixsyns, gate_mappings, special_gates, preferred,
             symbols):
  # First, tokenize the reported string, and then replace the reported tokens with preferred
  # tokens:
  tokenized_gates = tokenize(project, suffixsymbs, suffixsyns, reported)
  preferized_gates = preferize(tokenized_gates, gate_mappings, special_gates, preferred, symbols)
  return ', '.join(preferized_gates)


def write_records(records, headers, outfile, project, suffixsymbs, suffixsyns,
                  gate_mappings, special_gates, preferred, symbols):
  """
  Writes the given records, for which their keys are given in `headers`, to the given outfile.
  In addition, validate the population name and definition for each record and write the validation
  comments to the row corresponding to the record in the file.
  """
  validated = {}

  for record in records:
    # First write all the headers for data not generated by us:
    for header in headers:
      print('"{}"'.format(record[header]), end='\t', file=outfile)

    # Now generate the validation fields for populationNameReported, populationNamePreferred,
    # populationDefnitionReported, and populationDefnitionPreferred. Note the misspelling of
    # 'Defnition'. This is the way it is defined in ImmPort.
    for prefix in ['populationName', 'populationDefnition']:
      key = (record[prefix + 'Reported'], record[prefix + 'Preferred'])
      # Only validate a given reported-preferred combination if it hasn't already been validated:
      if key not in validated:
        validated[key] = {
          'Reported': validate(record[prefix + 'Reported'] or '',
                               project, suffixsymbs, suffixsyns, gate_mappings,
                               special_gates, preferred, symbols),
          'Preferred': validate(record[prefix + 'Preferred'] or '',
                                project, suffixsymbs, suffixsyns, gate_mappings,
                                special_gates, preferred, symbols)}

      print('"{}"\t"{}"'.format(validated[key]['Reported'], validated[key]['Preferred']),
            end='\t', file=outfile)

      if validated[key]['Reported'] == validated[key]['Preferred']:
        print('"Y"', end='\t', file=outfile)
      else:
        print('"N"', end='\t', file=outfile)

    # Write a new line to end off the record:
    print(file=outfile)


def main():
  # Basic command-line arguments:
  parser = argparse.ArgumentParser(description='''
  Accepts as input a list of study accession IDs corresponding to Cytometry studies (fcsAnalyzed).
  For each study indicated, its details are fetched from ImmPort and the population name and
  definition reported in the study are validated. The output of this script is a TSV file, reporting
  on the population name and definition used in the studies specified. In the report, the population
  name and definition reported in the study as well as the 'preferred' name and definition (i.e. the
  name and definition automatically generated by ImmPort when the study was submitted) are indcated.
  In addition to these columns, this script adds six extra columns: (a) the result of validating the
  reported population name, (b) the result of validating the preferred population name, (c) a
  comparison of the results of these two validations, (d) the result of validating the reported
  population definition, (b) the result of validating the preferred population definition, (c)
  a comparison of the results of these two validations.''')

  parser.add_argument('--username', metavar='USERNAME', type=str,
                      help='username for ImmPort API. If unspecified the script will prompt for it')
  parser.add_argument('--password', metavar='PASSWORD', type=str,
                      help='password for ImmPort API. If unspecified the script will prompt for it')
  parser.add_argument('--fcsAnalyzed', metavar='ID', type=str, nargs='+',
                      help='ids of Cytometry studies to validate (e.g., SDY113')
  parser.add_argument('--output_dir', metavar='DIR', type=str,
                      help='directory for output TSV files')
  parser.add_argument('--clobber', dest='clobber', action='store_true',
                      help='If output TSV files exist, overwrite them without prompting')

  required = parser.add_argument_group('required arguments')
  required.add_argument('--studiesinfo', metavar='TSV', required=True,
                        type=argparse.FileType(mode='r', encoding='ISO-8859-1'),
                        help='A TSV file containing general information on various studies')
  required.add_argument('--scale', metavar='TSV', required=True, type=argparse.FileType('r'),
                        help='a TSV file with the value scale (e.g. high, low, negative)')
  required.add_argument('--mappings', metavar='TSV', required=True, type=argparse.FileType('r'),
                        help='a TSV file which maps gate labels to ontology ids/keywords')
  required.add_argument('--special', metavar='TSV', required=True, type=argparse.FileType('r'),
                        help='a TSV file containing extra information about a subset of gates')
  required.add_argument('--preferred', metavar='TSV', required=True, type=argparse.FileType('r'),
                        help='a TSV file which maps ontology ids to preferred labels')

  args = vars(parser.parse_args())

  # If the username and/or password have not been specified on the command line, prompt for them:
  username = args['username']
  if not username:
    username = input("Enter username for API calls to ImmPort: ")
  password = args['password']
  if not password:
    password = getpass.getpass('Enter password for API calls to ImmPort: ')

  # If the study IDs have not been specified on the command line, prompt for them:
  fcsAnalyzed = args['fcsAnalyzed']
  if not fcsAnalyzed:
    fcsAnalyzed = input('Enter a list of Cytometry studies to validate (e.g. SDY113) separated by '
                        'whitespace: ').split()

  # Get the start time of the execution for later logging the total elapsed time:
  start = time.time()

  # Get an authentication token from ImmPort:
  print("Retrieving authentication token from Immport ...")
  resp = requests.post('https://auth.immport.org/auth/token',
                       data={'username': username, 'password': password})
  if resp.status_code != requests.codes.ok:
    resp.raise_for_status()
  token = resp.json()['token']

  # Read in the information from the file containing general info on studies:
  studiesinfo = csv.DictReader(args['studiesinfo'], delimiter='\t')

  # Extract the suffix synonyms and symbols from the scale TSV file:
  rows = csv.DictReader(args['scale'], delimiter='\t')
  suffixsymbs, suffixsyns = IriMaps.extract_suffix_syns_symbs_maps(rows)
  symbols = suffixsymbs.values()

  # Load the contents of the file given by the command-line parameter args.mappings.
  # This file associates gate laels with the ontology ids
  rows = csv.DictReader(args['mappings'], delimiter='\t')
  gate_mappings = {}
  for row in rows:
    gate_mappings[row['Label']] = row['Ontology ID']

  # Load the contents of the file given by the command-line parameter args.special.
  # This file (similary to the args.mapping file) associates certain gate labels with ontology ids
  # but also contains additional information regarding these gates.
  rows = csv.DictReader(args['special'], delimiter='\t')
  special_gates = {}
  for row in rows:
    special_gates[row['Label']] = {
      'Ontology ID': row['Ontology ID'],
      'Synonyms': row['Synonyms'],
      'Toxic Synonym': row['toxic synonym']}

  # Load the contents of the file given by the command-line parameter args.preferred.
  # This file associates ontology ids with preferred gate labels (i.e. pr#PRO-short-label).
  rows = csv.DictReader(args['preferred'], delimiter='\t')
  preferred = {}
  for row in rows:
    preferred[row['Ontology ID']] = row['Preferred Label']

  outpath = 'fcsAnalyzed-' + '-'.join(fcsAnalyzed) + '.tsv'
  outpath = args['output_dir'] + '/' + outpath if args['output_dir'] else outpath
  outpath = os.path.normpath(outpath)
  if os.path.exists(outpath) and args['clobber'] is False:
    reply = input(outpath + ' exists. Do you want really want to overwrite it? (y/n): ')
    reply = reply.lower().strip()
    if reply == 'n':
      sys.exit(1)

  with open(outpath, 'w') as outfile:
    query = ("https://api.immport.org/data/query/result/fcsAnalyzed?studyAccession={}"
             .format(','.join(fcsAnalyzed)))
    print("Sending request: " + query)
    resp = requests.get(query, headers={"Authorization": "bearer " + token})
    if resp.status_code != requests.codes.ok:
      resp.raise_for_status()

    # Make sure something came back:
    data = resp.json()
    if not data:
      print("No data returned.")
      sys.exit(1)

    # Write the header of the TSV using the data returned plus extra fields determined on its basis:
    headers = sorted([key for key in data[0]])
    for header in headers:
      print("{}".format(header), end='\t', file=outfile)
    print("Validated populationNameReported", end='\t', file=outfile)
    print("Validated populationNamePreferred", end='\t', file=outfile)
    print("Population name validations match", end='\t', file=outfile)
    print("Validated populationDefinitionReported", end='\t', file=outfile)
    print("Validated populationDefinitionPreferred", end='\t', file=outfile)
    print("Population definition validations match", file=outfile)

    # Now write the actual data:
    for sid in fcsAnalyzed:
      records = [r for r in resp.json() if r['studyAccession'] == sid]
      project = [s['Pis'] for s in studiesinfo if s['Supporting Data'] == sid][0]
      print("Received {} records for fcsAnalyzed ID: {}".format(len(records), sid))
      write_records(records, headers, outfile, project, suffixsymbs, suffixsyns,
                    gate_mappings, special_gates, preferred, symbols)

  end = time.time()
  print("Processing completed. Total execution time: {0:.2f} seconds.".format(end - start))


if __name__ == "__main__":
  main()


# Unit tests:

def test_validate():
  suffixsymbs = {
    'high': '++',
    'medium': '+~',
    'low': '+-',
    'positive': '+',
    'negative': '-'
  }

  symbols = suffixsymbs.values()

  suffixsyns = {
    'high': 'high',
    'hi': 'high',
    'bright': 'high',
    'Bright': 'high',
    'bri': 'high',
    'br': 'high',
    '(high)': 'high',
    'medium': 'medium',
    'med': 'medium',
    'intermediate': 'medium',
    'int': 'medium',
    '(medium)': 'medium',
    'low': 'low',
    'lo': 'low',
    'LO': 'low',
    'dim': 'low',
    'di': 'low',
    '(low)': 'low',
    'positive': 'positive',
    'negative': 'negative'
  }

  gate_mappings = {
    'Alexa350': 'http://purl.obolibrary.org/obo/PR_001',
    'Alexa750': 'http://purl.obolibrary.org/obo/PR_002',
    'Annexin': 'http://purl.obolibrary.org/obo/PR_003',
    'B220-_live': 'http://purl.obolibrary.org/obo/PR_004',
    'CCR7': 'http://purl.obolibrary.org/obo/PR_005',
    'CD14': 'http://purl.obolibrary.org/obo/PR_006',
    'CD16': 'http://purl.obolibrary.org/obo/PR_007',
    'CD19': 'http://purl.obolibrary.org/obo/PR_008',
    'CD20': 'http://purl.obolibrary.org/obo/PR_009',
    'CD21': 'http://purl.obolibrary.org/obo/PR_010',
    'CD24': 'http://purl.obolibrary.org/obo/PR_011',
    'CD27': 'http://purl.obolibrary.org/obo/PR_012',
    'CD3': 'http://purl.obolibrary.org/obo/PR_013',
    'CD33': 'http://purl.obolibrary.org/obo/PR_014',
    'CD38': 'http://purl.obolibrary.org/obo/PR_015',
    'CD4': 'http://purl.obolibrary.org/obo/PR_016',
    'CD44': 'http://purl.obolibrary.org/obo/PR_017',
    'CD45RA': 'http://purl.obolibrary.org/obo/PR_018',
    'CD4_T_cells': 'http://purl.obolibrary.org/obo/PR_019',
    'CD56': 'http://purl.obolibrary.org/obo/PR_020',
    'CD69': 'http://purl.obolibrary.org/obo/PR_021',
    'CD8': 'http://purl.obolibrary.org/obo/PR_022',
    'CD94': 'http://purl.obolibrary.org/obo/PR_023',
    'CXCR5': 'http://purl.obolibrary.org/obo/PR_024',
    'doublet_excluded': 'http://purl.obolibrary.org/obo/PR_025',
    'ICOS': 'http://purl.obolibrary.org/obo/PR_026',
    'IFNg': 'http://purl.obolibrary.org/obo/PR_027',
    'IL2': 'http://purl.obolibrary.org/obo/PR_028',
    'live': 'http://purl.obolibrary.org/obo/PR_029',
    'Live_cells': 'http://purl.obolibrary.org/obo/PR_030',
    'Lymph': 'http://purl.obolibrary.org/obo/PR_031',
    'Lymphocytes': 'http://purl.obolibrary.org/obo/PR_032',
    'lymphocytes': 'http://purl.obolibrary.org/obo/PR_033',
    'Michael': 'http://purl.obolibrary.org/obo/PR_034',
    'NP_tet': 'http://purl.obolibrary.org/obo/PR_035',
    'PD1': 'http://purl.obolibrary.org/obo/PR_036',
    'Robert': 'http://purl.obolibrary.org/obo/PR_037',
    'singlets': 'http://purl.obolibrary.org/obo/PR_038',
    'small_lymphocyte': 'http://purl.obolibrary.org/obo/PR_039',
    'SSC': 'http://purl.obolibrary.org/obo/PR_040',
    'TNFa': 'http://purl.obolibrary.org/obo/PR_041',
    'Uninfected': 'http://purl.obolibrary.org/obo/PR_042',
    'viable': 'http://purl.obolibrary.org/obo/PR_043',
  }

  special_gates = {
    'Michael': {'Ontology ID': 'PR:034', 'Synonyms': 'mike, mickey, mick',
                'Toxic Synonym': 'mikey'},
    'Robert': {'Ontology ID': 'PR:037', 'Synonyms': 'rob, bob, bert',
               'Toxic Synonym': 'bobert'}
  }

  preferred = {
    'http://purl.obolibrary.org/obo/PR_001': 'Axexa350',
    'http://purl.obolibrary.org/obo/PR_002': 'Alexa750',
    'http://purl.obolibrary.org/obo/PR_003': 'Annexin',
    'http://purl.obolibrary.org/obo/PR_004': 'B220-_live',
    'http://purl.obolibrary.org/obo/PR_005': 'CCR7',
    'http://purl.obolibrary.org/obo/PR_006': 'CD14',
    'http://purl.obolibrary.org/obo/PR_007': 'CD16',
    'http://purl.obolibrary.org/obo/PR_008': 'CD19',
    'http://purl.obolibrary.org/obo/PR_009': 'CD20',
    'http://purl.obolibrary.org/obo/PR_010': 'CD21',
    'http://purl.obolibrary.org/obo/PR_011': 'CD24',
    'http://purl.obolibrary.org/obo/PR_012': 'CD27',
    'http://purl.obolibrary.org/obo/PR_013': 'CD3',
    'http://purl.obolibrary.org/obo/PR_014': 'CD33',
    'http://purl.obolibrary.org/obo/PR_015': 'CD38',
    'http://purl.obolibrary.org/obo/PR_016': 'CD4',
    'http://purl.obolibrary.org/obo/PR_017': 'CD44',
    'http://purl.obolibrary.org/obo/PR_018': 'CD45RA',
    'http://purl.obolibrary.org/obo/PR_019': 'CD4_T_cells',
    'http://purl.obolibrary.org/obo/PR_020': 'CD56',
    'http://purl.obolibrary.org/obo/PR_021': 'CD69',
    'http://purl.obolibrary.org/obo/PR_022': 'CD8',
    'http://purl.obolibrary.org/obo/PR_023': 'CD94',
    'http://purl.obolibrary.org/obo/PR_024': 'CXCR5',
    'http://purl.obolibrary.org/obo/PR_025': 'doublet_excluded',
    'http://purl.obolibrary.org/obo/PR_026': 'ICOS',
    'http://purl.obolibrary.org/obo/PR_027': 'IFNg',
    'http://purl.obolibrary.org/obo/PR_028': 'IL2',
    'http://purl.obolibrary.org/obo/PR_029': 'live',
    'http://purl.obolibrary.org/obo/PR_030': 'Live_cells',
    'http://purl.obolibrary.org/obo/PR_031': 'Lymph',
    'http://purl.obolibrary.org/obo/PR_032': 'Lymphocytes',
    'http://purl.obolibrary.org/obo/PR_033': 'lymphocytes',
    'http://purl.obolibrary.org/obo/PR_035': 'NP_tet',
    'http://purl.obolibrary.org/obo/PR_036': 'PD1',
    'http://purl.obolibrary.org/obo/PR_038': 'singlets',
    'http://purl.obolibrary.org/obo/PR_039': 'small_lymphocyte',
    'http://purl.obolibrary.org/obo/PR_040': 'SSC',
    'http://purl.obolibrary.org/obo/PR_041': 'TNFa',
    'http://purl.obolibrary.org/obo/PR_042': 'Uninfected',
  }

  reported = 'CD14-CD56-CD3+CD4+CD8-CD45RA+CCR7+'
  preferized = validate(reported, 'LaJolla', suffixsymbs, suffixsyns, gate_mappings, special_gates,
                        preferred, symbols)
  assert preferized == 'CD14-, CD56-, CD3+, CD4+, CD8-, CD45RA+, CCR7+'
